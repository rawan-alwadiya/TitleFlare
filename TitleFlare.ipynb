{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5f9e-962a-4a8a-947b-b320b3a08f40",
   "metadata": {},
   "source": [
    "# **TitleFlare: Fine-Tuned T5 Model for AI-Powered Title Generation**\n",
    "\n",
    "## **Project Overview**\n",
    "**TitleFlare** is an advanced title generation system that transforms long-form articles into catchy, context-aware, and creative headlines.  \n",
    "Built on Google’s `t5-base` model and fine-tuned on a curated dataset of Medium articles, this project demonstrates how encoder-decoder architectures can be adapted for abstractive headline generation using the `transformers` library and the `Seq2SeqTrainer` framework.\n",
    "\n",
    "> **Note**: Model training and testing were conducted on **Google Colab**, utilizing GPU acceleration to speed up experimentation and evaluation.\n",
    "\n",
    "This project highlights the capability of fine-tuned generative models to assist in real-world content creation tasks by automating the generation of high-quality article titles.\n",
    "\n",
    "## **Objectives**\n",
    "- Fine-tune the `t5-base` model for headline generation.\n",
    "- Ensure contextual accuracy and creativity in generated titles.\n",
    "- Evaluate model quality using **ROUGE**.\n",
    "- Handle long and complex article inputs efficiently through preprocessing.\n",
    "\n",
    "## **Dataset**\n",
    "- **Source**: [Kaggle - Medium Articles Dataset](https://www.kaggle.com/datasets/arnabchaki/medium-articles-dataset)  \n",
    "- **Content**: Medium articles with titles and full body text.  \n",
    "- **Cleaning**: Basic filtering was applied to remove incomplete or low-quality entries.  \n",
    "- **Splits**: Training, validation, and test sets were created with stratified sampling.\n",
    "\n",
    "## **Technical Stack**\n",
    "- **Model Architecture**: T5-base  \n",
    "- **Training Framework**: Transformers Trainer API  \n",
    "- **Evaluation Metric**: ROUGE  \n",
    "- **Tools Used**: PyTorch, Google Colab, TensorBoard, KaggleHub  \n",
    "- **Preprocessing**: Custom text cleaner + sentence filtering to improve input quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b3457-0a69-4d6a-b16b-5f2fcd624aee",
   "metadata": {},
   "source": [
    "##### **Environment Setup & Requirements Installation**\n",
    "\n",
    "Installs dependencies and prepares the environment by downloading necessary files and packages for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bdaf4f0-42be-4eb9-8712-e7aa8ac2e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\omen\\anaconda3\\lib\\site-packages (2.21.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\omen\\anaconda3\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\omen\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\omen\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\omen\\anaconda3\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\omen\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\omen\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\omen\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers rouge-score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5836602-951a-49ad-a34d-b1b25ca7ed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\OMEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7740ebe1-4066-49fa-8abe-7ffdd03045ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\OMEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfc5620f-029b-4e57-9258-b670943a988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehubNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading kagglehub-0.3.4-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\omen\\anaconda3\\lib\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\omen\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\omen\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\omen\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.4\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1921431-1404-4192-859d-501e9ae97a5f",
   "metadata": {},
   "source": [
    "##### **Import Core Libraries**\n",
    "\n",
    "Imports key libraries from the `transformers` and `datasets` modules for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93507421-b63d-4fb9-8900-dc5f67d3b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ba0bb-a115-4c72-92ee-3b08aac3b0e0",
   "metadata": {},
   "source": [
    "##### **List Available Kaggle Datasets**\n",
    "\n",
    "Displays a list of datasets available on the authenticated Kaggle account to verify accessibility before downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2be4bc-0aa3-4cb3-994d-e3cb74735af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                        title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "---------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "bhadramohit/customer-shopping-latest-trends-dataset        Customer Shopping (Latest Trends) Dataset           76KB  2024-11-23 15:26:12           7752        143  1.0              \n",
      "malaiarasugraj/global-health-statistics                    Global Health Statistics                            44MB  2024-11-27 10:52:27           1949         27  1.0              \n",
      "mujtabamatin/air-quality-and-pollution-assessment          Air Quality and Pollution Assessment                84KB  2024-12-04 15:29:51           2304         43  1.0              \n",
      "hopesb/student-depression-dataset                          Student Depression Dataset.                        454KB  2024-11-22 17:56:03           4582         68  0.9411765        \n",
      "anirudhchauhan/retail-store-inventory-forecasting-dataset  Retail Store Inventory Forecasting Dataset           2MB  2024-11-24 20:09:48           2009         36  1.0              \n",
      "steve1215rogg/student-lifestyle-dataset                    student lifestyle dataset                           22KB  2024-11-11 19:11:28           9352        137  1.0              \n",
      "shreyasg23/life-expectancy-averaged-dataset                Life Expectancy Averaged Dataset                    11KB  2024-12-04 10:23:37           1003         26  0.9411765        \n",
      "steve1215rogg/e-commerce-dataset                           E-Commerce Dataset                                  90KB  2024-11-22 22:10:02           2820         48  1.0              \n",
      "ikynahidwin/depression-student-dataset                     Depression Student Dataset                           4KB  2024-11-20 06:42:01           5015         81  1.0              \n",
      "heidarmirhajisadati/germany-city-rainfall-data             Germany City Rainfall Data                          12KB  2024-12-04 22:20:48            474         22  1.0              \n",
      "harios/box-office-data-1984-to-2024-from-boxofficemojo     Box Office Data (1984 to 2024) from BoxOfficeMojo  123KB  2024-12-04 07:09:56            524         21  1.0              \n",
      "aditirai2607/super-market-dataset                          Super Market dataset                                 2MB  2024-11-26 14:04:03           1420         29  1.0              \n",
      "b'itzusama/apple-stock-market-data-2020-2024                 Apple Stock Market Data (2020-2024) \\xf0\\x9f\\x94\\xa5               35KB  2024-12-04 09:03:12            792         22  0.88235295       '\n",
      "heidarmirhajisadati/regional-cost-of-living-analysis       Regional Cost of Living Analysis                    13KB  2024-11-30 22:38:52           1137         66  1.0              \n",
      "mohitkumar282/used-car-dataset                             Used Car Dataset                                   230KB  2024-11-24 09:14:58           3161         40  1.0              \n",
      "b'pinuto/global-energy-generation-and-capacity-imf           \\xe2\\x9a\\xa1 Global Energy Generation & Capacity (IMF)        404KB  2024-12-01 21:44:05            690         30  1.0              '\n",
      "b'bushraqurban/world-education-dataset                       \\xf0\\x9f\\x8c\\x8d World Education Dataset \\xf0\\x9f\\x93\\x9a                        243KB  2024-11-22 20:05:15           1619         28  1.0              '\n",
      "abdocan/laptop-prices                                      Laptop Prices                                       19KB  2024-12-03 17:26:51            596         25  0.7058824        \n",
      "junnn0126/university-students-mental-health                University Students' Mental Health                  11KB  2024-11-25 15:07:26           1708         28  0.8235294        \n",
      "ironwolf437/electric-vehicle-population-in-usa             Electric Vehicle Population in USA                   6MB  2024-11-30 15:53:33            478         26  1.0              \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed89f78-129a-4229-ae21-969890059f0e",
   "metadata": {},
   "source": [
    "##### **Download Medium Articles Dataset from Kaggle**\n",
    "\n",
    "Downloads the Medium Articles dataset ZIP file directly using its Kaggle identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c36d08c-106b-4a57-a768-cb257c29e4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/fabiochiusano/medium-articles\n",
      "License(s): CC0-1.0\n",
      "Downloading medium-articles.zip to C:\\Users\\OMEN\\TitleFlare\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/369M [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/369M [00:01<06:40, 964kB/s]\n",
      "  1%|          | 2.00M/369M [00:02<07:07, 900kB/s]\n",
      "  1%|          | 3.00M/369M [00:03<07:27, 857kB/s]\n",
      "  1%|1         | 4.00M/369M [00:05<08:07, 785kB/s]\n",
      "  1%|1         | 5.00M/369M [00:06<08:34, 742kB/s]\n",
      "  2%|1         | 6.00M/369M [00:08<08:54, 711kB/s]\n",
      "  2%|1         | 7.00M/369M [00:10<09:43, 650kB/s]\n",
      "  2%|2         | 8.00M/369M [00:11<09:50, 641kB/s]\n",
      "  2%|2         | 9.00M/369M [00:13<10:07, 621kB/s]\n",
      "  3%|2         | 10.0M/369M [00:14<09:26, 665kB/s]\n",
      "  3%|2         | 11.0M/369M [00:16<09:48, 638kB/s]\n",
      "  3%|3         | 12.0M/369M [00:18<10:06, 617kB/s]\n",
      "  4%|3         | 13.0M/369M [00:20<10:32, 590kB/s]\n",
      "  4%|3         | 14.0M/369M [00:22<10:16, 603kB/s]\n",
      "  4%|4         | 15.0M/369M [00:23<09:36, 644kB/s]\n",
      "  4%|4         | 16.0M/369M [00:25<09:27, 652kB/s]\n",
      "  5%|4         | 17.0M/369M [00:26<09:51, 624kB/s]\n",
      "  5%|4         | 18.0M/369M [00:28<10:06, 606kB/s]\n",
      "  5%|5         | 19.0M/369M [00:30<09:51, 620kB/s]\n",
      "  5%|5         | 20.0M/369M [00:32<09:49, 620kB/s]\n",
      "  6%|5         | 21.0M/369M [00:33<09:27, 643kB/s]\n",
      "  6%|5         | 22.0M/369M [00:35<09:25, 643kB/s]\n",
      "  6%|6         | 23.0M/369M [00:36<09:06, 664kB/s]\n",
      "  7%|6         | 24.0M/369M [00:38<09:18, 648kB/s]\n",
      "  7%|6         | 25.0M/369M [00:39<09:00, 668kB/s]\n",
      "  7%|7         | 26.0M/369M [00:41<08:54, 673kB/s]\n",
      "  7%|7         | 27.0M/369M [00:42<08:38, 691kB/s]\n",
      "  8%|7         | 28.0M/369M [00:44<08:35, 693kB/s]\n",
      "  8%|7         | 29.0M/369M [00:45<08:29, 699kB/s]\n",
      "  8%|8         | 30.0M/369M [00:47<08:40, 682kB/s]\n",
      "  8%|8         | 31.0M/369M [00:48<08:26, 699kB/s]\n",
      "  9%|8         | 32.0M/369M [00:50<09:24, 626kB/s]\n",
      "  9%|8         | 33.0M/369M [00:52<08:58, 654kB/s]\n",
      "  9%|9         | 34.0M/369M [00:53<08:27, 693kB/s]\n",
      "  9%|9         | 35.0M/369M [00:55<08:18, 703kB/s]\n",
      " 10%|9         | 36.0M/369M [00:56<07:59, 728kB/s]\n",
      " 10%|#         | 37.0M/369M [00:57<08:10, 709kB/s]\n",
      " 10%|#         | 38.0M/369M [00:59<08:41, 665kB/s]\n",
      " 11%|#         | 39.0M/369M [01:01<09:23, 614kB/s]\n",
      " 11%|#         | 40.0M/369M [01:03<09:09, 628kB/s]\n",
      " 11%|#1        | 41.0M/369M [01:04<08:28, 676kB/s]\n",
      " 11%|#1        | 42.0M/369M [01:06<08:19, 687kB/s]\n",
      " 12%|#1        | 43.0M/369M [01:07<08:24, 677kB/s]\n",
      " 12%|#1        | 44.0M/369M [01:09<07:59, 711kB/s]\n",
      " 12%|#2        | 45.0M/369M [01:10<07:45, 730kB/s]\n",
      " 12%|#2        | 46.0M/369M [01:11<07:30, 751kB/s]\n",
      " 13%|#2        | 47.0M/369M [01:13<08:32, 659kB/s]\n",
      " 13%|#3        | 48.0M/369M [01:15<08:07, 690kB/s]\n",
      " 13%|#3        | 49.0M/369M [01:16<08:00, 697kB/s]\n",
      " 14%|#3        | 50.0M/369M [01:18<07:55, 703kB/s]\n",
      " 14%|#3        | 51.0M/369M [01:19<07:40, 724kB/s]\n",
      " 14%|#4        | 52.0M/369M [01:20<07:53, 702kB/s]\n",
      " 14%|#4        | 53.0M/369M [01:22<08:20, 662kB/s]\n",
      " 15%|#4        | 54.0M/369M [01:24<07:58, 690kB/s]\n",
      " 15%|#4        | 55.0M/369M [01:25<07:51, 698kB/s]\n",
      " 15%|#5        | 56.0M/369M [01:27<07:47, 701kB/s]\n",
      " 15%|#5        | 57.0M/369M [01:28<08:02, 678kB/s]\n",
      " 16%|#5        | 58.0M/369M [01:30<07:36, 715kB/s]\n",
      " 16%|#5        | 59.0M/369M [01:31<08:06, 668kB/s]\n",
      " 16%|#6        | 60.0M/369M [01:33<08:11, 659kB/s]\n",
      " 17%|#6        | 61.0M/369M [01:35<08:07, 662kB/s]\n",
      " 17%|#6        | 62.0M/369M [01:37<08:43, 614kB/s]\n",
      " 17%|#7        | 63.0M/369M [01:39<09:24, 568kB/s]\n",
      " 17%|#7        | 64.0M/369M [01:41<10:37, 501kB/s]\n",
      " 18%|#7        | 65.0M/369M [01:43<10:17, 516kB/s]\n",
      " 18%|#7        | 66.0M/369M [01:45<09:21, 566kB/s]\n",
      " 18%|#8        | 67.0M/369M [01:46<09:09, 576kB/s]\n",
      " 18%|#8        | 68.0M/369M [01:48<08:34, 613kB/s]\n",
      " 19%|#8        | 69.0M/369M [01:49<08:19, 629kB/s]\n",
      " 19%|#8        | 70.0M/369M [01:51<07:46, 671kB/s]\n",
      " 19%|#9        | 71.0M/369M [01:52<07:34, 687kB/s]\n",
      " 20%|#9        | 72.0M/369M [01:54<07:59, 650kB/s]\n",
      " 20%|#9        | 73.0M/369M [01:56<07:47, 663kB/s]\n",
      " 20%|##        | 74.0M/369M [01:57<07:38, 675kB/s]\n",
      " 20%|##        | 75.0M/369M [01:59<08:16, 621kB/s]\n",
      " 21%|##        | 76.0M/369M [02:01<09:22, 546kB/s]\n",
      " 21%|##        | 77.0M/369M [02:04<09:33, 534kB/s]\n",
      " 21%|##1       | 78.0M/369M [02:05<08:58, 566kB/s]\n",
      " 21%|##1       | 79.0M/369M [02:06<08:08, 623kB/s]\n",
      " 22%|##1       | 80.0M/369M [02:08<07:53, 639kB/s]\n",
      " 22%|##1       | 81.0M/369M [02:09<07:37, 660kB/s]\n",
      " 22%|##2       | 82.0M/369M [02:11<07:21, 682kB/s]\n",
      " 22%|##2       | 83.0M/369M [02:13<07:41, 650kB/s]\n",
      " 23%|##2       | 84.0M/369M [02:14<07:18, 682kB/s]\n",
      " 23%|##3       | 85.0M/369M [02:17<09:08, 542kB/s]\n",
      " 23%|##3       | 86.0M/369M [02:19<09:10, 539kB/s]\n",
      " 24%|##3       | 87.0M/369M [02:21<09:19, 528kB/s]\n",
      " 24%|##3       | 88.0M/369M [02:22<08:39, 567kB/s]\n",
      " 24%|##4       | 89.0M/369M [02:24<08:13, 595kB/s]\n",
      " 24%|##4       | 90.0M/369M [02:25<07:36, 641kB/s]\n",
      " 25%|##4       | 91.0M/369M [02:27<07:21, 660kB/s]\n",
      " 25%|##4       | 92.0M/369M [02:29<07:43, 626kB/s]\n",
      " 25%|##5       | 93.0M/369M [02:30<07:13, 668kB/s]\n",
      " 25%|##5       | 94.0M/369M [02:32<07:06, 675kB/s]\n",
      " 26%|##5       | 95.0M/369M [02:33<07:33, 633kB/s]\n",
      " 26%|##6       | 96.0M/369M [02:35<07:23, 646kB/s]\n",
      " 26%|##6       | 97.0M/369M [02:36<06:57, 683kB/s]\n",
      " 27%|##6       | 98.0M/369M [02:38<06:51, 690kB/s]\n",
      " 27%|##6       | 99.0M/369M [02:39<06:39, 709kB/s]\n",
      " 27%|##7       | 100M/369M [02:41<06:54, 680kB/s] \n",
      " 27%|##7       | 101M/369M [02:42<06:57, 673kB/s]\n",
      " 28%|##7       | 102M/369M [02:45<08:20, 559kB/s]\n",
      " 28%|##7       | 103M/369M [02:47<07:47, 596kB/s]\n",
      " 28%|##8       | 104M/369M [02:48<07:30, 617kB/s]\n",
      " 28%|##8       | 105M/369M [02:50<07:30, 614kB/s]\n",
      " 29%|##8       | 106M/369M [02:52<08:10, 562kB/s]\n",
      " 29%|##9       | 107M/369M [02:54<07:43, 593kB/s]\n",
      " 29%|##9       | 108M/369M [02:55<07:05, 643kB/s]\n",
      " 30%|##9       | 109M/369M [02:56<06:56, 655kB/s]\n",
      " 30%|##9       | 110M/369M [02:58<07:08, 634kB/s]\n",
      " 30%|###       | 111M/369M [03:01<08:40, 520kB/s]\n",
      " 30%|###       | 112M/369M [03:03<08:27, 531kB/s]\n",
      " 31%|###       | 113M/369M [03:05<08:19, 537kB/s]\n",
      " 31%|###       | 114M/369M [03:06<07:43, 577kB/s]\n",
      " 31%|###1      | 115M/369M [03:08<07:24, 599kB/s]\n",
      " 31%|###1      | 116M/369M [03:10<07:18, 604kB/s]\n",
      " 32%|###1      | 117M/369M [03:11<07:08, 616kB/s]\n",
      " 32%|###1      | 118M/369M [03:13<07:22, 594kB/s]\n",
      " 32%|###2      | 119M/369M [03:15<07:51, 555kB/s]\n",
      " 33%|###2      | 120M/369M [03:17<07:27, 583kB/s]\n",
      " 33%|###2      | 121M/369M [03:18<06:57, 623kB/s]\n",
      " 33%|###3      | 122M/369M [03:20<06:39, 648kB/s]\n",
      " 33%|###3      | 123M/369M [03:22<07:03, 609kB/s]\n",
      " 34%|###3      | 124M/369M [03:23<06:38, 644kB/s]\n",
      " 34%|###3      | 125M/369M [03:25<07:00, 609kB/s]\n",
      " 34%|###4      | 126M/369M [03:27<06:40, 636kB/s]\n",
      " 34%|###4      | 127M/369M [03:28<06:22, 663kB/s]\n",
      " 35%|###4      | 128M/369M [03:30<06:27, 652kB/s]\n",
      " 35%|###4      | 129M/369M [03:32<07:12, 582kB/s]\n",
      " 35%|###5      | 130M/369M [03:33<06:41, 624kB/s]\n",
      " 36%|###5      | 131M/369M [03:35<06:16, 662kB/s]\n",
      " 36%|###5      | 132M/369M [03:36<06:06, 678kB/s]\n",
      " 36%|###6      | 133M/369M [03:38<05:51, 705kB/s]\n",
      " 36%|###6      | 134M/369M [03:39<05:45, 713kB/s]\n",
      " 37%|###6      | 135M/369M [03:41<06:28, 631kB/s]\n",
      " 37%|###6      | 136M/369M [03:43<06:45, 602kB/s]\n",
      " 37%|###7      | 137M/369M [03:45<06:57, 582kB/s]\n",
      " 37%|###7      | 138M/369M [03:47<06:39, 607kB/s]\n",
      " 38%|###7      | 139M/369M [03:48<06:37, 607kB/s]\n",
      " 38%|###7      | 140M/369M [03:50<06:16, 638kB/s]\n",
      " 38%|###8      | 141M/369M [03:51<06:07, 649kB/s]\n",
      " 38%|###8      | 142M/369M [03:53<06:06, 649kB/s]\n",
      " 39%|###8      | 143M/369M [03:55<06:40, 591kB/s]\n",
      " 39%|###9      | 144M/369M [03:57<07:04, 555kB/s]\n",
      " 39%|###9      | 145M/369M [03:59<06:55, 565kB/s]\n",
      " 40%|###9      | 146M/369M [04:01<06:55, 562kB/s]\n",
      " 40%|###9      | 147M/369M [04:03<06:54, 562kB/s]\n",
      " 40%|####      | 148M/369M [04:04<06:32, 590kB/s]\n",
      " 40%|####      | 149M/369M [04:06<06:11, 621kB/s]\n",
      " 41%|####      | 150M/369M [04:07<06:01, 634kB/s]\n",
      " 41%|####      | 151M/369M [04:09<06:04, 626kB/s]\n",
      " 41%|####1     | 152M/369M [04:11<06:39, 569kB/s]\n",
      " 41%|####1     | 153M/369M [04:13<06:25, 588kB/s]\n",
      " 42%|####1     | 154M/369M [04:16<07:35, 495kB/s]\n",
      " 42%|####2     | 155M/369M [04:18<07:58, 469kB/s]\n",
      " 42%|####2     | 156M/369M [04:20<07:06, 524kB/s]\n",
      " 43%|####2     | 157M/369M [04:22<06:45, 547kB/s]\n",
      " 43%|####2     | 158M/369M [04:23<06:07, 601kB/s]\n",
      " 43%|####3     | 159M/369M [04:25<06:09, 595kB/s]\n",
      " 43%|####3     | 160M/369M [04:26<06:11, 590kB/s]\n",
      " 44%|####3     | 161M/369M [04:28<05:55, 613kB/s]\n",
      " 44%|####3     | 162M/369M [04:30<05:40, 637kB/s]\n",
      " 44%|####4     | 163M/369M [04:31<05:28, 656kB/s]\n",
      " 44%|####4     | 164M/369M [04:33<05:19, 672kB/s]\n",
      " 45%|####4     | 165M/369M [04:34<05:16, 675kB/s]\n",
      " 45%|####4     | 166M/369M [04:35<05:02, 702kB/s]\n",
      " 45%|####5     | 167M/369M [04:37<05:28, 644kB/s]\n",
      " 46%|####5     | 168M/369M [04:39<05:13, 673kB/s]\n",
      " 46%|####5     | 169M/369M [04:41<05:43, 610kB/s]\n",
      " 46%|####6     | 170M/369M [04:43<05:57, 583kB/s]\n",
      " 46%|####6     | 171M/369M [04:44<05:35, 619kB/s]\n",
      " 47%|####6     | 172M/369M [04:46<05:22, 640kB/s]\n",
      " 47%|####6     | 173M/369M [04:47<05:16, 648kB/s]\n",
      " 47%|####7     | 174M/369M [04:49<05:11, 656kB/s]\n",
      " 47%|####7     | 175M/369M [04:51<05:18, 639kB/s]\n",
      " 48%|####7     | 176M/369M [04:52<05:07, 657kB/s]\n",
      " 48%|####7     | 177M/369M [04:54<05:02, 665kB/s]\n",
      " 48%|####8     | 178M/369M [04:55<05:05, 654kB/s]\n",
      " 49%|####8     | 179M/369M [04:59<07:14, 458kB/s]\n",
      " 49%|####8     | 180M/369M [05:01<06:54, 477kB/s]\n",
      " 49%|####9     | 181M/369M [05:03<06:48, 482kB/s]\n",
      " 49%|####9     | 182M/369M [05:06<07:00, 466kB/s]\n",
      " 50%|####9     | 183M/369M [05:08<07:07, 456kB/s]\n",
      " 50%|####9     | 184M/369M [05:10<06:48, 474kB/s]\n",
      " 50%|#####     | 185M/369M [05:13<06:55, 465kB/s]\n",
      " 50%|#####     | 186M/369M [05:15<07:17, 438kB/s]\n",
      " 51%|#####     | 187M/369M [05:18<07:12, 441kB/s]\n",
      " 51%|#####     | 188M/369M [05:20<07:09, 441kB/s]\n",
      " 51%|#####1    | 189M/369M [05:22<06:29, 484kB/s]\n",
      " 52%|#####1    | 190M/369M [05:24<06:13, 503kB/s]\n",
      " 52%|#####1    | 191M/369M [05:26<06:13, 500kB/s]\n",
      " 52%|#####2    | 192M/369M [05:28<06:15, 494kB/s]\n",
      " 52%|#####2    | 193M/369M [05:30<06:25, 478kB/s]\n",
      " 53%|#####2    | 194M/369M [05:33<07:00, 436kB/s]\n",
      " 53%|#####2    | 195M/369M [05:34<06:04, 500kB/s]\n",
      " 53%|#####3    | 196M/369M [05:36<05:28, 553kB/s]\n",
      " 53%|#####3    | 197M/369M [05:37<05:03, 594kB/s]\n",
      " 54%|#####3    | 198M/369M [05:39<04:41, 636kB/s]\n",
      " 54%|#####3    | 199M/369M [05:40<04:33, 651kB/s]\n",
      " 54%|#####4    | 200M/369M [05:42<04:47, 615kB/s]\n",
      " 54%|#####4    | 201M/369M [05:44<04:44, 618kB/s]\n",
      " 55%|#####4    | 202M/369M [05:45<04:23, 664kB/s]\n",
      " 55%|#####5    | 203M/369M [05:47<04:24, 658kB/s]\n",
      " 55%|#####5    | 204M/369M [05:48<04:21, 661kB/s]\n",
      " 56%|#####5    | 205M/369M [05:50<04:26, 644kB/s]\n",
      " 56%|#####5    | 206M/369M [05:52<04:22, 652kB/s]\n",
      " 56%|#####6    | 207M/369M [05:53<04:18, 658kB/s]\n",
      " 56%|#####6    | 208M/369M [05:55<04:23, 640kB/s]\n",
      " 57%|#####6    | 209M/369M [05:56<04:17, 651kB/s]\n",
      " 57%|#####6    | 210M/369M [05:58<04:15, 652kB/s]\n",
      " 57%|#####7    | 211M/369M [06:00<04:16, 646kB/s]\n",
      " 57%|#####7    | 212M/369M [06:02<04:39, 589kB/s]\n",
      " 58%|#####7    | 213M/369M [06:04<05:00, 543kB/s]\n",
      " 58%|#####8    | 214M/369M [06:10<07:48, 346kB/s]\n",
      " 58%|#####8    | 215M/369M [06:14<09:00, 298kB/s]\n",
      " 59%|#####8    | 216M/369M [06:18<09:04, 294kB/s]\n",
      " 59%|#####8    | 217M/369M [06:24<10:25, 255kB/s]\n",
      " 59%|#####9    | 218M/369M [06:27<09:55, 266kB/s]\n",
      " 59%|#####9    | 219M/369M [06:29<08:04, 325kB/s]\n",
      " 60%|#####9    | 220M/369M [06:30<06:56, 374kB/s]\n",
      " 60%|#####9    | 221M/369M [06:32<06:06, 423kB/s]\n",
      " 60%|######    | 222M/369M [06:34<05:26, 472kB/s]\n",
      " 60%|######    | 223M/369M [06:36<05:35, 457kB/s]\n",
      " 61%|######    | 224M/369M [06:38<05:18, 477kB/s]\n",
      " 61%|######    | 225M/369M [06:40<04:58, 505kB/s]\n",
      " 61%|######1   | 226M/369M [06:42<04:42, 531kB/s]\n",
      " 62%|######1   | 227M/369M [06:43<04:23, 566kB/s]\n",
      " 62%|######1   | 228M/369M [06:45<04:11, 588kB/s]\n",
      " 62%|######2   | 229M/369M [06:46<04:00, 610kB/s]\n",
      " 62%|######2   | 230M/369M [06:48<03:53, 625kB/s]\n",
      " 63%|######2   | 231M/369M [06:50<03:44, 644kB/s]\n",
      " 63%|######2   | 232M/369M [06:51<03:37, 660kB/s]\n",
      " 63%|######3   | 233M/369M [06:53<03:37, 657kB/s]\n",
      " 63%|######3   | 234M/369M [06:55<04:01, 586kB/s]\n",
      " 64%|######3   | 235M/369M [06:57<03:54, 599kB/s]\n",
      " 64%|######3   | 236M/369M [06:58<03:42, 628kB/s]\n",
      " 64%|######4   | 237M/369M [07:00<03:35, 642kB/s]\n",
      " 65%|######4   | 238M/369M [07:01<03:38, 628kB/s]\n",
      " 65%|######4   | 239M/369M [07:04<03:56, 576kB/s]\n",
      " 65%|######5   | 240M/369M [07:05<03:50, 587kB/s]\n",
      " 65%|######5   | 241M/369M [07:07<03:43, 601kB/s]\n",
      " 66%|######5   | 242M/369M [07:09<03:35, 616kB/s]\n",
      " 66%|######5   | 243M/369M [07:10<03:22, 651kB/s]\n",
      " 66%|######6   | 244M/369M [07:11<03:15, 669kB/s]\n",
      " 66%|######6   | 245M/369M [07:13<03:14, 669kB/s]\n",
      " 67%|######6   | 246M/369M [07:16<03:56, 544kB/s]\n",
      " 67%|######6   | 247M/369M [07:17<03:41, 576kB/s]\n",
      " 67%|######7   | 248M/369M [07:19<03:28, 609kB/s]\n",
      " 67%|######7   | 249M/369M [07:20<03:17, 638kB/s]\n",
      " 68%|######7   | 250M/369M [07:23<03:38, 570kB/s]\n",
      " 68%|######8   | 251M/369M [07:24<03:40, 560kB/s]\n",
      " 68%|######8   | 252M/369M [07:27<03:47, 538kB/s]\n",
      " 69%|######8   | 253M/369M [07:28<03:34, 567kB/s]\n",
      " 69%|######8   | 254M/369M [07:30<03:24, 591kB/s]\n",
      " 69%|######9   | 255M/369M [07:32<03:50, 517kB/s]\n",
      " 69%|######9   | 256M/369M [07:35<04:12, 469kB/s]\n",
      " 70%|######9   | 257M/369M [07:38<04:24, 443kB/s]\n",
      " 70%|######9   | 258M/369M [07:40<04:32, 427kB/s]\n",
      " 70%|#######   | 259M/369M [07:44<05:00, 383kB/s]\n",
      " 70%|#######   | 260M/369M [07:49<06:15, 304kB/s]\n",
      " 71%|#######   | 261M/369M [07:51<05:40, 332kB/s]\n",
      " 71%|#######1  | 262M/369M [07:53<04:55, 379kB/s]\n",
      " 71%|#######1  | 263M/369M [07:56<04:48, 385kB/s]\n",
      " 72%|#######1  | 264M/369M [07:59<05:05, 360kB/s]\n",
      " 72%|#######1  | 265M/369M [08:02<04:51, 373kB/s]\n",
      " 72%|#######2  | 266M/369M [08:04<04:25, 406kB/s]\n",
      " 72%|#######2  | 267M/369M [08:06<03:53, 458kB/s]\n",
      " 73%|#######2  | 268M/369M [08:07<03:34, 492kB/s]\n",
      " 73%|#######2  | 269M/369M [08:09<03:13, 540kB/s]\n",
      " 73%|#######3  | 270M/369M [08:12<03:50, 449kB/s]\n",
      " 73%|#######3  | 271M/369M [08:14<03:23, 503kB/s]\n",
      " 74%|#######3  | 272M/369M [08:15<03:03, 553kB/s]\n",
      " 74%|#######4  | 273M/369M [08:17<02:51, 587kB/s]\n",
      " 74%|#######4  | 274M/369M [08:19<03:01, 548kB/s]\n",
      " 75%|#######4  | 275M/369M [08:20<02:52, 572kB/s]\n",
      " 75%|#######4  | 276M/369M [08:23<03:00, 540kB/s]\n",
      " 75%|#######5  | 277M/369M [08:24<02:57, 542kB/s]\n",
      " 75%|#######5  | 278M/369M [08:26<02:48, 565kB/s]\n",
      " 76%|#######5  | 279M/369M [08:28<02:38, 596kB/s]\n",
      " 76%|#######5  | 280M/369M [08:29<02:35, 598kB/s]\n",
      " 76%|#######6  | 281M/369M [08:31<02:26, 628kB/s]\n",
      " 76%|#######6  | 282M/369M [08:32<02:20, 646kB/s]\n",
      " 77%|#######6  | 283M/369M [08:34<02:16, 661kB/s]\n",
      " 77%|#######6  | 284M/369M [08:36<02:17, 647kB/s]\n",
      " 77%|#######7  | 285M/369M [08:38<02:27, 598kB/s]\n",
      " 78%|#######7  | 286M/369M [08:39<02:20, 620kB/s]\n",
      " 78%|#######7  | 287M/369M [08:41<02:16, 628kB/s]\n",
      " 78%|#######8  | 288M/369M [08:42<02:14, 632kB/s]\n",
      " 78%|#######8  | 289M/369M [08:44<02:20, 596kB/s]\n",
      " 79%|#######8  | 290M/369M [08:46<02:14, 617kB/s]\n",
      " 79%|#######8  | 291M/369M [08:48<02:08, 637kB/s]\n",
      " 79%|#######9  | 292M/369M [08:49<02:09, 623kB/s]\n",
      " 79%|#######9  | 293M/369M [08:51<02:05, 635kB/s]\n",
      " 80%|#######9  | 294M/369M [08:54<02:25, 539kB/s]\n",
      " 80%|#######9  | 295M/369M [08:58<03:18, 391kB/s]\n",
      " 80%|########  | 296M/369M [08:59<02:50, 449kB/s]\n",
      " 81%|########  | 297M/369M [09:03<03:24, 369kB/s]\n",
      " 81%|########  | 298M/369M [09:05<02:54, 426kB/s]\n",
      " 81%|########1 | 299M/369M [09:07<02:50, 429kB/s]\n",
      " 81%|########1 | 300M/369M [09:09<02:28, 487kB/s]\n",
      " 82%|########1 | 301M/369M [09:11<02:29, 475kB/s]\n",
      " 82%|########1 | 302M/369M [09:13<02:19, 502kB/s]\n",
      " 82%|########2 | 303M/369M [09:14<02:03, 557kB/s]\n",
      " 82%|########2 | 304M/369M [09:16<01:52, 604kB/s]\n",
      " 83%|########2 | 305M/369M [09:18<01:50, 606kB/s]\n",
      " 83%|########2 | 306M/369M [09:20<02:00, 550kB/s]\n",
      " 83%|########3 | 307M/369M [09:22<01:55, 560kB/s]\n",
      " 83%|########3 | 308M/369M [09:23<01:50, 577kB/s]\n",
      " 84%|########3 | 309M/369M [09:25<01:40, 626kB/s]\n",
      " 84%|########4 | 310M/369M [09:26<01:35, 650kB/s]\n",
      " 84%|########4 | 311M/369M [09:28<01:36, 629kB/s]\n",
      " 85%|########4 | 312M/369M [09:30<01:33, 639kB/s]\n",
      " 85%|########4 | 313M/369M [09:31<01:30, 648kB/s]\n",
      " 85%|########5 | 314M/369M [09:33<01:28, 649kB/s]\n",
      " 85%|########5 | 315M/369M [09:35<01:32, 610kB/s]\n",
      " 86%|########5 | 316M/369M [09:36<01:27, 635kB/s]\n",
      " 86%|########5 | 317M/369M [09:39<01:36, 563kB/s]\n",
      " 86%|########6 | 318M/369M [09:42<01:51, 481kB/s]\n",
      " 86%|########6 | 319M/369M [09:43<01:39, 528kB/s]\n",
      " 87%|########6 | 320M/369M [09:44<01:29, 575kB/s]\n",
      " 87%|########7 | 321M/369M [09:46<01:24, 597kB/s]\n",
      " 87%|########7 | 322M/369M [09:48<01:20, 613kB/s]\n",
      " 88%|########7 | 323M/369M [09:50<01:24, 567kB/s]\n",
      " 88%|########7 | 324M/369M [09:52<01:28, 532kB/s]\n",
      " 88%|########8 | 325M/369M [09:54<01:29, 515kB/s]\n",
      " 88%|########8 | 326M/369M [09:56<01:21, 552kB/s]\n",
      " 89%|########8 | 327M/369M [09:57<01:15, 584kB/s]\n",
      " 89%|########8 | 328M/369M [10:00<01:17, 556kB/s]\n",
      " 89%|########9 | 329M/369M [10:01<01:10, 591kB/s]\n",
      " 89%|########9 | 330M/369M [10:03<01:10, 579kB/s]\n",
      " 90%|########9 | 331M/369M [10:05<01:07, 592kB/s]\n",
      " 90%|########9 | 332M/369M [10:06<01:01, 630kB/s]\n",
      " 90%|######### | 333M/369M [10:08<01:03, 591kB/s]\n",
      " 91%|######### | 334M/369M [10:10<01:01, 593kB/s]\n",
      " 91%|######### | 335M/369M [10:12<01:00, 586kB/s]\n",
      " 91%|#########1| 336M/369M [10:13<00:57, 595kB/s]\n",
      " 91%|#########1| 337M/369M [10:15<00:52, 632kB/s]\n",
      " 92%|#########1| 338M/369M [10:16<00:48, 663kB/s]\n",
      " 92%|#########1| 339M/369M [10:18<00:47, 665kB/s]\n",
      " 92%|#########2| 340M/369M [10:20<00:48, 631kB/s]\n",
      " 92%|#########2| 341M/369M [10:21<00:44, 660kB/s]\n",
      " 93%|#########2| 342M/369M [10:23<00:42, 656kB/s]\n",
      " 93%|#########2| 343M/369M [10:25<00:44, 616kB/s]\n",
      " 93%|#########3| 344M/369M [10:27<00:48, 539kB/s]\n",
      " 94%|#########3| 345M/369M [10:29<00:47, 523kB/s]\n",
      " 94%|#########3| 346M/369M [10:31<00:42, 563kB/s]\n",
      " 94%|#########4| 347M/369M [10:33<00:40, 573kB/s]\n",
      " 94%|#########4| 348M/369M [10:35<00:39, 557kB/s]\n",
      " 95%|#########4| 349M/369M [10:36<00:36, 570kB/s]\n",
      " 95%|#########4| 350M/369M [10:38<00:32, 608kB/s]\n",
      " 95%|#########5| 351M/369M [10:41<00:39, 480kB/s]\n",
      " 95%|#########5| 352M/369M [10:43<00:35, 498kB/s]\n",
      " 96%|#########5| 353M/369M [10:45<00:32, 509kB/s]\n",
      " 96%|#########5| 354M/369M [10:46<00:28, 554kB/s]\n",
      " 96%|#########6| 355M/369M [10:48<00:25, 573kB/s]\n",
      " 97%|#########6| 356M/369M [10:50<00:22, 604kB/s]\n",
      " 97%|#########6| 357M/369M [10:51<00:20, 603kB/s]\n",
      " 97%|#########7| 358M/369M [10:53<00:18, 605kB/s]\n",
      " 97%|#########7| 359M/369M [10:55<00:16, 612kB/s]\n",
      " 98%|#########7| 360M/369M [10:56<00:14, 645kB/s]\n",
      " 98%|#########7| 361M/369M [10:58<00:13, 618kB/s]\n",
      " 98%|#########8| 362M/369M [10:59<00:11, 641kB/s]\n",
      " 98%|#########8| 363M/369M [11:01<00:10, 610kB/s]\n",
      " 99%|#########8| 364M/369M [11:04<00:09, 528kB/s]\n",
      " 99%|#########8| 365M/369M [11:06<00:07, 569kB/s]\n",
      " 99%|#########9| 366M/369M [11:07<00:05, 608kB/s]\n",
      " 99%|#########9| 367M/369M [11:09<00:03, 594kB/s]\n",
      "100%|#########9| 368M/369M [11:11<00:01, 585kB/s]\n",
      "100%|##########| 369M/369M [11:12<00:00, 597kB/s]\n",
      "100%|##########| 369M/369M [11:12<00:00, 575kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d fabiochiusano/medium-articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981cb1eb-5d9b-423d-ab73-9d3b5823c8f6",
   "metadata": {},
   "source": [
    "##### **Load Dataset Directory via KaggleHub**\n",
    "\n",
    "Retrieves the full path to the downloaded dataset using KaggleHub, which simplifies data access within the Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48d605e5-e31f-466b-a9bb-b5d55eb45dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/fabiochiusano/medium-articles?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 369M/369M [12:44<00:00, 506kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\OMEN\\.cache\\kagglehub\\datasets\\fabiochiusano\\medium-articles\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"fabiochiusano/medium-articles\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d37a1-6650-4dff-902f-16028ab9e6fc",
   "metadata": {},
   "source": [
    "##### **Load Dataset into Hugging Face Format**\n",
    "\n",
    "Loads the Medium Articles CSV data using Hugging Face’s `load_dataset` for easier preprocessing and training integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96fbfae-51c8-41bc-85eb-1cedd21d6610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b684041132ae409baa14b7175e450967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "medium_datasets = load_dataset(\"csv\", data_files=\"medium-articles.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3803cd60-1752-4357-abb7-0297b9db9bea",
   "metadata": {},
   "source": [
    "##### **Filter Incomplete Records**\n",
    "\n",
    "Removes any dataset entries that are missing either the article `text` or the `title` to ensure clean training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa025fd-0432-48e7-85ec-097a72a3793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f94306571c42b58021d1022eccea09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/186368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ef22d0bbbb4d3787cef87bb3a4470c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cf8294d8304bf08f0c7330dcfa0345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "medium_datasets_cleaned = medium_datasets.filter(lambda x: x['text'] is not None and x['title'] is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25a112-eaaf-421d-9c53-e74b42281747",
   "metadata": {},
   "source": [
    "##### **Split Dataset into Train, Validation, and Test Sets**\n",
    "\n",
    "Performs stratified splitting:  \n",
    "- Reserves `3,000` samples for testing.  \n",
    "- Then reserves another `3,000` from the training portion for validation.  \n",
    "Updates the main dataset dictionary accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0383acf6-3ae4-4bb1-9f71-1949ceb7eb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'text', 'url', 'authors', 'timestamp', 'tags'],\n",
       "        num_rows: 180363\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'text', 'url', 'authors', 'timestamp', 'tags'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'text', 'url', 'authors', 'timestamp', 'tags'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_train_test = medium_datasets_cleaned[\"train\"].train_test_split(test_size=3000)\n",
    "datasets_train_validation = datasets_train_test[\"train\"].train_test_split(test_size=3000)\n",
    "\n",
    "medium_datasets[\"train\"] = datasets_train_validation[\"train\"]\n",
    "medium_datasets[\"validation\"] = datasets_train_validation[\"test\"]\n",
    "medium_datasets[\"test\"] = datasets_train_test[\"test\"]\n",
    "\n",
    "medium_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f078a65-6112-40fc-9f25-ac1f1108e441",
   "metadata": {},
   "source": [
    "##### **Display Dataset Split Statistics**\n",
    "\n",
    "Calculates and prints the percentage distribution of training, validation, and test samples to verify the dataset balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16a2b672-d6f7-4200-8836-e6ed1f6d11fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training set: 96.78%\n",
      "- Validation set: 1.61%\n",
      "- Test set: 1.61%\n"
     ]
    }
   ],
   "source": [
    "n_samples_train = len(medium_datasets[\"train\"])\n",
    "n_samples_validation = len(medium_datasets[\"validation\"])\n",
    "n_samples_test = len(medium_datasets[\"test\"])\n",
    "n_samples_total = n_samples_train + n_samples_validation + n_samples_test\n",
    "\n",
    "print(f\"- Training set: {n_samples_train*100/n_samples_total:.2f}%\")\n",
    "print(f\"- Validation set: {n_samples_validation*100/n_samples_total:.2f}%\")\n",
    "print(f\"- Test set: {n_samples_test*100/n_samples_total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4006b-d003-4f91-abe8-00ddcfa70e99",
   "metadata": {},
   "source": [
    "##### **Load Tokenizer and Model Checkpoint**\n",
    "\n",
    "Imports the tokenizer associated with the `t5-base` model from Hugging Face’s Transformers library to tokenize both inputs and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22e179ba-c422-4a88-b4af-9310a766c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0f8cd-91b2-4c11-9101-b4b1d6a6d2b4",
   "metadata": {},
   "source": [
    "##### **Set Text Preprocessing Configuration**\n",
    "\n",
    "Defines prefix and max sequence lengths used for preparing model input and output sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a8c9a9d-d0ba-4471-a724-2b321fa165f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd44be48-2609-4e57-a896-865c5568fdf5",
   "metadata": {},
   "source": [
    "##### **Text Cleaning and Preprocessing Functions**\n",
    "\n",
    "Defines functions to clean raw article content and tokenize both the input text and corresponding titles.  \n",
    "Filters out malformed sentence fragments and prepares data in the format expected by the `T5` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406b3aaf-5292-477c-bc8f-62c4726181d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 64\n",
    "\n",
    "def clean_text(text):\n",
    "  sentences = nltk.sent_tokenize(text.strip())\n",
    "  sentences_cleaned = [s for sent in sentences for s in sent.split(\"\\n\")]\n",
    "  sentences_cleaned_no_titles = [sent for sent in sentences_cleaned\n",
    "                                 if len(sent) > 0 and\n",
    "                                 sent[-1] in string.punctuation]\n",
    "  text_cleaned = \"\\n\".join(sentences_cleaned_no_titles)\n",
    "  return text_cleaned\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  texts_cleaned = [clean_text(text) for text in examples[\"text\"]]\n",
    "  inputs = [prefix + text for text in texts_cleaned]\n",
    "  model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "  # Setup the tokenizer for targets\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer(examples[\"title\"], max_length=max_target_length, \n",
    "                       truncation=True)\n",
    "\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c7a79-eb1c-493f-9427-3b192b0c4fd2",
   "metadata": {},
   "source": [
    "##### **Dataset Filtering and Tokenization**\n",
    "\n",
    "Applies a length-based filter to exclude incomplete entries, followed by tokenization using the defined preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3db336b7-5feb-434c-a3ce-31e371f8a26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73061167bd1e440a84967395b5bbec33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/154380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'text', 'url', 'authors', 'timestamp', 'tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 154380\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'text', 'url', 'authors', 'timestamp', 'tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2589\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'text', 'url', 'authors', 'timestamp', 'tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2557\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_datasets_cleaned = medium_datasets.filter(lambda example: (len(example['text']) >= 500) and (len(example['title']) >= 20))\n",
    "tokenized_datasets = medium_datasets_cleaned.map(preprocess_data, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc4c41-f750-4948-bd00-833289fc5758",
   "metadata": {},
   "source": [
    "##### **Define Training Arguments and Configuration**\n",
    "\n",
    "Sets up training hyperparameters, checkpointing, logging strategies, and evaluation settings for the `Seq2SeqTrainer` using the `t5-base` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d738ed53-a583-44a3-973a-60049bb37bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\OMEN\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d288fa6-936b-4ca0-80c0-cc4b388bbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_name = \"t5-base-medium-title-generation\"\n",
    "model_dir = \"/content/Models/t5-base-medium-title-generation\"\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    model_dir,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b253e-c0b0-448d-ada2-e37a81e02364",
   "metadata": {},
   "source": [
    "##### **Initialize Data Collator for Seq2Seq**\n",
    "\n",
    "Creates a data collator that dynamically pads inputs and labels during training, ensuring compatibility with sequence-to-sequence models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b7008e-e406-4156-b731-aa34cc7610c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a679a27-cff3-4334-8d01-b142cfe3fa43",
   "metadata": {},
   "source": [
    "##### **Define ROUGE-Based Evaluation Metrics**\n",
    "\n",
    "Implements the `compute_metrics` function using ROUGE scores to evaluate the quality of generated headlines. Also tracks the average length of generated sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76dc409b-4076-47e3-897b-faebf1f7af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "# Load the ROUGE metric with trust_remote_code\n",
    "metric = load(\"rouge\", trust_remote_code=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
    "                      for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) \n",
    "                      for label in decoded_labels]\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n",
    "                            use_stemmer=True)\n",
    "\n",
    "    # Extract ROUGE f1 scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length to metrics\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
    "                      for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8d230-4df3-4b6a-a7f9-1c3aff483489",
   "metadata": {},
   "source": [
    "##### **Load Pretrained T5 Model**\n",
    "\n",
    "Loads the base T5 model for sequence-to-sequence learning using the specified checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f788724c-f1f1-4a45-a9e6-fcfed999ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2144e-4693-476e-a9e6-8b81b53ad8bf",
   "metadata": {},
   "source": [
    "##### **Initialize Trainer Object**\n",
    "\n",
    "Configures the `Seq2SeqTrainer` with model, datasets, training arguments, tokenizer, and evaluation metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87618f82-dc6e-4265-9a94-7ddd904fb89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb29456-bc85-468b-a9c3-5392a84a685b",
   "metadata": {},
   "source": [
    "##### **Launch TensorBoard for Live Monitoring**\n",
    "\n",
    "Starts TensorBoard interface to track training metrics and visualize progress during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3c8c3-b906-4e60-9e54-ee710b809a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TensorBoard before training to monitor it in progress\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '{model_dir}'/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35688d4f-5081-4565-bdb8-ae77ac9d9627",
   "metadata": {},
   "source": [
    "##### **Fine-Tune the T5 Model**\n",
    "\n",
    "Fine-tunes the pretrained `T5` model on the Medium articles dataset using custom training arguments, evaluation steps, and ROUGE-based performance monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bac30f-0775-42b6-8b3d-71047857390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d8a0b-fb0a-4b3b-9eb3-62990fcc80cd",
   "metadata": {},
   "source": [
    "##### **Save Trained Model Locally**\n",
    "\n",
    "Persists the fine-tuned model and tokenizer to the specified directory for later use or export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae3977-7f79-4b20-bdce-01ab506e169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af41dd5-e750-4441-8666-ee2c9cdb6565",
   "metadata": {},
   "source": [
    "##### **Archive and Download Trained Model**\n",
    "\n",
    "Compresses the saved model directory into a ZIP file and initiates download to the local machine using Colab utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa0e64-5141-45ce-9f6a-7e5e42f83aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab (Optional)\n",
    "!zip -r model.zip /content/Models/t5-base-medium-title-generation\n",
    "from google.colab import files\n",
    "files.download(\"model.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8d7ee-86d3-4088-96e3-c30d8ec98f47",
   "metadata": {},
   "source": [
    "##### **Reload Model and Tokenizer from Saved Directory**\n",
    "\n",
    "Restores the tokenizer and model from local storage, preparing them for inference or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dee5c-869a-4411-946c-9e1864cf1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from GDrive\n",
    "model_dir = \"/content/Models/t5-base-medium-title-generation\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd6a50-cbcf-44ba-ad73-3f5b0f09f95d",
   "metadata": {},
   "source": [
    "##### **Set Inference Parameters**\n",
    "\n",
    "Defines the maximum input length used during title generation or inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712b9ab-ef87-4114-9ac1-efc4091cb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952559e7-81cf-496b-bbe5-c97de51f0b58",
   "metadata": {},
   "source": [
    "##### **Generate Title from Sample Article** \n",
    "\n",
    "Uses the fine-tuned `T5` model to generate a headline for a sample article input. Applies beam search decoding with sampling to enhance creativity in title generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069571c-a376-40bd-beb3-42d24d10f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "We define access to a Streamlit app in a browser tab as a session.\n",
    "For each browser tab that connects to the Streamlit server, a new session is created.\n",
    "Streamlit reruns your script from top to bottom every time you interact with your app.\n",
    "Each reruns takes place in a blank slate: no variables are shared between runs.\n",
    "Session State is a way to share variables between reruns, for each user session.\n",
    "In addition to the ability to store and persist state, Streamlit also exposes the\n",
    "ability to manipulate state using Callbacks. In this guide, we will illustrate the\n",
    "usage of Session State and Callbacks as we build a stateful Counter app.\n",
    "For details on the Session State and Callbacks API, please refer to our Session\n",
    "State API Reference Guide. Also, check out this Session State basics tutorial\n",
    "video by Streamlit Developer Advocate Dr. Marisa Smith to get started:\n",
    "\"\"\"\n",
    "\n",
    "inputs = [\"summarize: \" + text]\n",
    "\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_title)\n",
    "# Session State and Callbacks in Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f18f9d-d276-4742-850b-3b5d0f21c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Many financial institutions started building conversational AI, prior to the Covid19\n",
    "pandemic, as part of a digital transformation initiative. These initial solutions\n",
    "were high profile, highly personalized virtual assistants — like the Erica chatbot\n",
    "from Bank of America. As the pandemic hit, the need changed as contact centers were\n",
    "under increased pressures. As Cathal McGloin of ServisBOT explains in “how it started,\n",
    "and how it is going,” financial institutions were looking for ways to automate\n",
    "solutions to help get back to “normal” levels of customer service. This resulted\n",
    "in a change from the “future of conversational AI” to a real tactical assistant\n",
    "that can help in customer service. Haritha Dev of Wells Fargo, saw a similar trend.\n",
    "Banks were originally looking to conversational AI as part of digital transformation\n",
    "to keep up with the times. However, with the pandemic, it has been more about\n",
    "customer retention and customer satisfaction. In addition, new use cases came about\n",
    "as a result of Covid-19 that accelerated adoption of conversational AI. As Vinita\n",
    "Kumar of Deloitte points out, banks were dealing with an influx of calls about new\n",
    "concerns, like questions around the Paycheck Protection Program (PPP) loans. This\n",
    "resulted in an increase in volume, without enough agents to assist customers, and\n",
    "tipped the scale to incorporate conversational AI. When choosing initial use cases\n",
    "to support, financial institutions often start with high volume, low complexity\n",
    "tasks. For example, password resets, checking account balances, or checking the\n",
    "status of a transaction, as Vinita points out. From there, the use cases can evolve\n",
    "as the banks get more mature in developing conversational AI, and as the customers\n",
    "become more engaged with the solutions. Cathal indicates another good way for banks\n",
    "to start is looking at use cases that are a pain point, and also do not require a\n",
    "lot of IT support. Some financial institutions may have a multi-year technology\n",
    "roadmap, which can make it harder to get a new service started. A simple chatbot\n",
    "for document collection in an onboarding process can result in high engagement,\n",
    "and a high return on investment. For example, Cathal has a banking customer that\n",
    "implemented a chatbot to capture a driver’s license to be used in the verification\n",
    "process of adding an additional user to an account — it has over 85% engagement\n",
    "with high satisfaction. An interesting use case Haritha discovered involved\n",
    "educating customers on financial matters. People feel more comfortable asking a\n",
    "chatbot what might be considered a “dumb” question, as the chatbot is less judgmental.\n",
    "Users can be more ambiguous with their questions as well, not knowing the right\n",
    "words to use, as chatbot can help narrow things down.\n",
    "\"\"\"\n",
    "\n",
    "inputs = [\"summarize: \" + text]\n",
    "\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_title)\n",
    "# Conversational AI: The Future of Customer Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e3a45-5264-4b93-a5aa-7830e233c59a",
   "metadata": {},
   "source": [
    "##### **Evaluate Model Performance on Test Set**\n",
    "\n",
    "Preprocesses the test set, batches the inputs, and generates predictions using the trained `T5` model.  \n",
    "Computes **ROUGE-based evaluation metrics** by comparing generated titles to reference titles in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d554f-a6eb-4b45-82be-d99bf6265a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# get test split\n",
    "test_tokenized_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "# pad texts to the same length\n",
    "def preprocess_test(examples):\n",
    "  inputs = [prefix + text for text in examples[\"text\"]]\n",
    "  model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n",
    "                           padding=\"max_length\")\n",
    "  return model_inputs\n",
    "\n",
    "test_tokenized_dataset = test_tokenized_dataset.map(preprocess_test, batched=True)\n",
    "\n",
    "# prepare dataloader\n",
    "test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=32)\n",
    "\n",
    "# generate text for each batch\n",
    "all_predictions = []\n",
    "for i,batch in enumerate(dataloader):\n",
    "  predictions = model.generate(**batch)\n",
    "  all_predictions.append(predictions)\n",
    "\n",
    "# flatten predictions\n",
    "all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n",
    "\n",
    "# tokenize and pad titles\n",
    "all_titles = tokenizer(test_tokenized_dataset[\"title\"], max_length=max_target_length,\n",
    "                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "\n",
    "# compute metrics\n",
    "predictions_labels = [all_predictions_flattened, all_titles]\n",
    "compute_metrics(predictions_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f239f3f-f7d6-47fb-9982-e4bb2329f0dd",
   "metadata": {},
   "source": [
    "## **Final Thoughts**\n",
    "\n",
    "This project demonstrates how powerful transformer-based models like `T5` can be customized for specialized NLP tasks beyond summarization — in this case, **headline generation**.\n",
    "\n",
    "Despite being trained on a **limited dataset** and within **Colab constraints**, **TitleFlare** achieves strong performance and reflects the potential of fine-tuned generative models in creative applications. Its combination of **rigorous preprocessing**, **effective evaluation with ROUGE**, and **elegant model architecture** makes it a solid base for future development or production deployment.\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for checking out TitleFlare**.  \n",
    "Feel free to explore the code and adapt it for your own **NLP content generation** tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
